---
title: "Hausaufgabe 2: Deskriptives"
author: "Simon Krukowski & Kira Wolff"
---

# Beschreibung

Diese Woche habt ihr euch im Seminar mit dem Einlesen von Daten, dem Zurechtschnibbeln von Dataframes, dem Aufbereiten deskriptiver Ergebnisse und dem Erstellen von Plots beschäftigt. Wie letzte Woche wollen wir euch hier einiges wiederholen, kombinieren und weiterdenken lassen.

Falls ihr an einer Stelle mal nicht weiterkommen solltet, sodass die folgenden Aufgaben nicht mehr lösbar sind, meldet euch bitte bei uns.

### Punkte

Für jede Aufgabe bzw. Teilaufgabe gibt es Punkte - diese sind entsprechend kenntlich gemacht. Insgesamt gibt es für jedes Aufgabenblatt 10 Punkte. Aufgaben, die als **\[Bonus\]** markiert sind, geben keine Punkte.

### Für Experten

Manche Aufgaben erfordern Transferwissen, welches ihr im heutigen Seminar so nicht direkt gelernt hat. Diese Aufgaben sind als **\[Für Experten\]** markiert - hier berücksichtigen wir nicht nur die Lösung, sondern schon eure Lösungsversuche (falls ihr auf keine Lösung kommt).

### Abgabe \[+ .html\]

Um eure Hausaufgabe abzugeben, ladet diese bitte als `.qmd` Datei im Moodle hoch. Etwaige anderer Dateien (.html, assets-Ordner) müsst ihr nicht hochladen. Bitte benennt die Dateien entsprechend (bspw. `hausaufgabe2_simon_krukowski.qmd`, und schreibt hier in der Datei oben bei `author` euren Namen rein.

# Aufgaben

### Aufgabe 1 \[1 Punkt\]

In der letzten Seminarstunde habt ihr einiges über statistische Verfahren in R gelernt. In dieser Hausaufgabe geht es darum, dieses Wissenanzuwenden. In der Stunde habt ihr außerdem gelernt, warum es wichtig und sinnvoll ist, zu Beginn eines jeden Quarto-Dokuments einen "Info-Chunk" zu erstellen, in dem ihr alle benötigten Packages aktiviert etc.

Erstellt nun einen solchen Chunk und nennt ihn `preliminaries`. Ladet darin das Package `datarium` (installiert es vorher ggf. über die Konsole), sowie alle weiteren Packages, die ihr benötigt. Speichert das darin enthaltene Dataset `genderweight` als `dataset`.

Außerdem kann es hilfreich sein, dort direkt eine Farbpalette (bspw. mit 4 Farben, definiert als hex codes) in einem Vektor zu speichern. Holt euch bspw. bei colorhunt.co Inspiration und speichert eine solche Palette darin ab.

Stellt außerdem sicher, dass der Chunk keine Warnungen anzeigt beim rendern (hint: chunk-options).

```{r}

```

### Aufgabe 2 \[1 Punkt\]

Schaut euch den Datensatz an, um ein Gefühl dafür zu bekommen. Gebt euch dazu wahlweise den Datensatz selbst, oder bspw. gruppierte Outputs über `dplyr` an. Wir wollen, dass die Tabellenoutputs nicht im default Format dargestellt werden. Stellt das entsprechend im YAML Header ein.

```{r}

```

### Aufgabe 3 \[1 Punkt\]

Prüft nun die Variable `weight` auf Normalverteilung. Macht das wahlweise über einen Test, oder ein Diagramm:

```{r}

```

Ist die Variable normalverteilt? Begründe kurz:

*Antwort hier*

### Aufgabe 4 \[1 Punkt\]

Unabhängig davon, was wir gerade herausgefunden haben, entscheiden wir uns dazu, einen t-Test zu rechnen, und die Mittelwerte von `weight` miteinander zu vergleichen. Wir haben die Vermutung, dass Männer ein höheres Gewicht haben. Berücksichtigt das und rechnet den Test (hint: gerichtetes Testen). Was kommt heraus?

```{r}

```

*Antwort hier*

### Bonus:

Was hat die Überschrift zu bedeuten und wie könnte das mit Voraussetzungen zu tun haben?

*Antwort hier*

### Aufgabe 5 \[1 Punkt\]

Angenommen, wir hätten in der Zwischenzeit herausgefunden, dass die Variable `weight` nicht normalverteilt ist. Welcher Test bietet sich dann stattdessen an? Rechnet diesen.

```{r}

```

### Aufgabe 6 \[1 Punkt\]

-\> Anova mit CO2 und Messwiederholung -\> Long/Wide?

```{r}

```

### Aufgabe 7 \[1 Punkt\]

-\> Boxplot? -\> Palette verwenden

### Aufgabe 8 \[1 Punkt\]

Wir interessieren uns nun auch für Zusammenhänge zwischen Daten. Dazu schauen wir uns wieder das bekannte `iris` data set an. Primär interessiert uns, ob `Sepal.Width` und `Sepal.Height` zusammenhängen. Um also zunächst eine Idee über die Verteilung der Daten zu bekommen, sollt ihr mit `ggplot` ein Diagramm erstellen. Darin sollen mehrere Sachen enthalten sein:

-   Bivariates Streudiagramm (hint: ihr wollt Punkte plotten)

-   Eine Regressionsgrade (hint: `geom_smooth()` ist euer Freund)

```{r}

```

Rechnet auch eine Pearson-Korrelation zwischen den beiden Variablen:

```{r}

```

Was lässt sich über den Zusammenhang der beiden Variablen sagen?

*Antwort hier*

### Aufgabe 9 \[1 Punkt\]

Wir haben nun die Annahme, dass die Spezies der Pflanzen außerdem einen Einfluss auf den Zusammenhang zwischen den beiden Variablen hat. Dazu sollt ihr zunächst die Punkte in Abhängigkeit von `Species` einfärben:

```{r}

```

Wir haben nun das Gefühl, dass ein Zusammenhang zwischen den beiden Variablen besteht und uns dazu entschieden, ein Regressionsmodell zu berechnen, in dem wir `Sepal.Length` als abhängige Variable haben, sowie `Species` und `Sepal.Width` als Prädiktoren. Berechnet ein solches Modell und speichert es als `model`:

```{r}

```

### Aufgabe 10 \[1 Punkt\]

Nun wollen wir die Ergebnisse der Regressionsanalyse entsprechend berichten. Aus Übungsgründen sollt ihr dabei auf Packages wie `stargazer()` verzichten. Ihr habt im Seminar inline-Code gelernt. Verwendet diesen, um die Ergebnisse entsprechend zu berichten. Dazu bietet es sich an, den Output von `summary()` in einem Objekt zu speichern, und dann auf die Werte zuzugreifen. Denkt dran: über den `$` Operator sowie `['variable']` könnt ihr auf einzelne Werte zugreifen.

```{r}

```

Ergänzt also die F-Statistik in folgendem Satz:

> Die Regression mit *Sepal.Width* als abhängige und *Sepal.Length* und *Species* als erklärende Variablen ist signifikant, *F* (3,146) = `antwort hier`, *p* \< .001.

### Aufgabe 11 \[Bonus\]

Was macht die `paste0` Funktion und könnte man die obige Lösung damit vereinfachen?


