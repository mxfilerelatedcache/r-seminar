---
title: "Inferenzstatistik in R"
author: "Kira Wolff & Simon Krukowski"
format: html
editor: visual
---

```{r packages}
#| warning: FALSE
library(tidyverse)
library(rstatix)
library(ggplot2)
library(car)
library(nycflights13)
```

# Statistik

Hier beschäftigen wir uns mit den grundlegenden inferenzstatistischen Verfahren, die ihr aus den Bachelor-Vorlesungen Statistik 1 und 2 kennt.

Das ist natürlich nur ein kleiner Einblick in die statistischen Verfahren, die mit R möglich sind. Es soll euch aber schon mal ein Gefühl für den grundlegenden Aufbau der Funktionen geben, sodass ihr ohne große Probleme auch andere Verfahren benutzen könnt. In vielen Fällen kommt man mit den grundlegenden Verfahren hier auch schon relativ weit.

## Die Qual der Wahl

Ähnlich wie ihr letzte Woche die Unterschiede zwischen base R und dplyr kennengelernt habt, gibt es auch für die inferenzstatistischen Verfahren verschiedene Packages und Funktionen, und damit Vorgehensweisen.

Grundsätzlich gibt es hier keine richtigen oder falschen Packages, stattdessen hängt es vom Kontext ab. Manche Packages ermöglichen ziemlich komplexe Analysen, und um sich die als Möglichkeit offen zu lassen, kann es sich lohnen, auch direkt die "einfachen" Analysen eines Projekts damit zu rechnen, damit die verschiedenen Analysen kompatibler miteinander sind. Manche Packages sind von der Syntax möglichst eingängig gestaltet, sodass man als Anfänger besser abgeholt wird. Wiederum andere bieten die gleichen Funktionen, verwenden aber leicht unterschiedliche Berechnungsmethoden, da die Methoden für verschiedene Kontexte verschieden robust sind.

Meistens macht es Sinn mit dem, was man kennt (bzw. was ihr hier kennenlernt), anzufangen. Wenn sich dann eine Datensituation ergibt, die komplexer ist, lässt sich immer noch im Internet recherchieren, welches Package/welche Funktion vielleicht besser geeignet sind. Die Hürde wird dann weniger euer R-Wissen sein, sondern eher euer allgemeines Statistik-Wissen. Unserer Erfahrung nach verbringt man eher mehr Zeit mit der Recherche von statistischen Methoden statt R-Funktionen.

Wie machen wir es hier? Wir zeigen euch die Funktionen von base R und vom Package `rstatix`, welches bewusst so gestaltet ist, damit es gut mit der Pipe und den dplyr-Funktionen funktioniert.

## Voraussetzungen

Wie ihr wisst, gibt es für die sogennannten parametrischen Testverfahren bestimmte Voraussetzungen, die die Daten erfüllen sollten, damit die Tests anwendbar sind und die Auswertung angemessen. Vorbildlich wie wir sind, schauen wir uns diese Tests für die Voraussetzungen zuerst an.

### Normalverteilung

```{r}
plot(dnorm, xlim=c(-3,3))
```

```{r}
#| eval: FALSE
# base
shapiro.test(Daten$Spalte)

# rstatix
data %>% 
  shapiro_test(Spalte)
```

Der Shapiro-Wilk Test testet, ob die Daten signifikant von einer Normalverteilung abweichen. Wenn er signifikant wird, sind die Daten also nicht normalverteilt.

Je größer die Stichprobe ist, desto schlechter funktioniert der Shapiro-Wilk Test, da er dann tendenziell zu schnell signifikant wird, obwohl die Daten einigermaßen normalverteilt sind. Daher bietet es sich an, ab ca. n \> 50 stattdessen einen QQ-Plot anzuschauen. Ab n \> 5000 würde der Test nicht mehr ausgeführt werden.

```{r}
# normalverteilte Werte erzeugen
vec.norm <- rnorm(1000, mean = 0, sd=1)

# QQ-Plot
ggplot()+
  geom_qq(aes(sample=vec.norm))+
  theme_minimal()
```

```{r}
shapiro.test(vec.norm)
```

Bei einem QQ-Plot werden die Werte, die wir testen, standardisiert und dann gegen die "echte" Standardnormalverteilung geplottet. Wenn unsere Daten perfekt (standard)normalverteilt wären, würde sich eine perfekte 45°-Gerade ergeben. Unsere künstlichen Daten oben sind auf jeden Fall nah genug an der "perfekten Gerade" dran.

Hier noch ein Beispiel, in dem die Daten nicht normalverteilt sind:

```{r}
# Daten aus nycflights13 package
ggplot(flights)+
  geom_qq(aes(sample=air_time))+
  theme_minimal()

flights

ggplot(flights)+
  geom_qq(aes(sample=dep_delay))+
  theme_minimal()

hist(flights$dep_delay)
```

### Varianzhomogenität

Bei der Varianzhomogenität geht es darum, dass unterschiedliche Gruppen bezüglich einer Variable die in etwa gleiche Varianz haben.

```{r}
#| eval: FALSE
# rstatix
data %>% 
  levene_test(abhängigeVariable ~ Gruppe)

flights %>% 
  levene_test(dep_delay ~ factor(month))


```

## Gruppenvergleiche

### t-Test

Ziel: zwei Gruppen vergleichen

Datenstruktur: kontinuierliche abhängige Variable & dichotome Gruppenvariable

Zur Veranschaulichung verwenden wir hier den Datensatz `ToothGrowth`: Hier wurde der Zahnwachstum von Meerschweinchen in Abhängigkeit von verabreichtem Vitamin C untersucht. Die Stichprobe besteht aus 60 Meerschweinchen und sowohl die Verabreichungsmethode (Orangensaft vs. Ascorbinsäure) als auch die Vitamin C-Dosis (0.5, 1 oder 2mg pro Tag) wurden variiert. Da wir beim t-Test nur mit zwei Gruppen arbeiten können, schauen wir uns jetzt nur die Unterschiede durch die Verabreichungsmethode an.

```{r ttest data}
summary(ToothGrowth)

view(ToothGrowth)

ToothGrowth %>% 
  get_summary_stats()

tooth <- ToothGrowth %>% 
            mutate(dose = as.factor(dose))
```

```{r}
ggplot(tooth)+
  geom_boxplot(aes(x=supp, y=len))+
  theme_minimal()
```

#### Funktionsaufbau

```{r}
#| eval=F

# Base: Format 1
t.test(AV ~ group, data)

# Base: Format 2
t.test(daten$group1, daten$group2)

# rstatix
data %>% 
  t_test(AV ~ group)
```

Die Tilde `~` ist das Zeichen in R, um einen Zusammenhang, eine Abhängigkeit oder ein Modell zu symbolisieren.

Natürlich gibt es innerhalb von `t.test()/t_test()` mit Argumenten Möglichkeiten um

-   einen t-Test für eine Stichprobe durchzuführen: z.B. `mu = 100`

-   einen t-Test für abhängige Stichproben durchzuführen: `paired = TRUE`

-   einen gerichteten t-Test durchzuführen: z.B. `alternative = "less"`

-   bei nicht vorliegender Varianzhomogenität stattdessen den Welch-Test anzuwenden: `var.equal = FALSE`

#### Funktionsanwendung

```{r}
# Base: Format 1
t.base <- t.test(len ~ supp, tooth, var.equal = TRUE)
t.base

# rstatix
t.rstatix <- tooth %>% 
                t_test(len ~ supp,var.equal = TRUE)
t.rstatix

# Normalerweise würde ich die Ergebnisse nicht als Objekte speichern, dient hier nur der Demonstration.
```

Unterschied zwischen base und rstatix:

-   Liste vs. tibble

-   base: Zusatzinfos - Zuordnung, Verständnis

-   rstatix: Formatierung als Tabelle

-   rstatix garantiert pipe-Kompatibilität, funktioniert bei Base-Funktionen nicht immer (aber manchmal)

Euch wird im Laufe der kommenden Funktionen auffallen, dass die `rstatix` Funktionen netterweise fast immer exakt so heißen wie die `base` Funktionen, nur das statt `.` ein `_` verwendet wird: `t.test()` vs. `t_test()`

#### Nonparametrisch: Wilcoxon Rank Sum Test

Reminder: Wenn Voraussetzungen nicht erfüllt sein sollten.

```{r}
# Base
wilcox.test(len ~ supp, tooth)

# rstatix
tooth %>% 
  wilcox_test(len ~ supp)
```

### ANOVA

Ziel: Zwei oder mehr Gruppen vergleichen.

Wir können hier bei den Meerschweinchendaten bleiben, da die Dosis-Variable drei Faktorstufen hat.

```{r anova}
#base
tooth.aov <- aov(len ~ dose, tooth)
summary(tooth.aov)

#funktioniert nicht:

#tooth %>% 
#  aov(len ~ dose) %>% 
#  summary()


#rstatix
## Schreibweise 1
tooth %>%
  anova_test(len ~ dose)

## Schreibweise 2
tooth %>%
  anova_test(dv = len,
             between = dose)


# Hybrid aus base und rstatix
anova_summary(tooth.aov)
```

Die Funktion `aov()` steht natürlich für "analysis of variances". Die Funktion gibt uns nicht direkt das Ergebnis, was wir von einer ANOVA erwarten, sondern fittet (="baut") erst mal nur das Modell. Wenn wir das ANOVA-Modell auswerten wollen, müssen wir uns das aov-Ergebnis über `summary()` zusammenfassen lassen.

Die Funktion `anova_test()` gibt uns direkt das erwartete Ergebnis aus. Innerhalb der Funktion gibt es zwei mögliche Schreibweisen, um das Modell zu spezifizieren: Entweder über die Tilde, oder indem wir Rollen der Variablen separat über die Argumente spezifizieren.

```{r}
# Hybrid aus base und rstatix
anova_summary(tooth.aov)
```

`anova_summary()` kann Outputs von `aov()` verwerten und verpackt sie in das praktische dataframe-Format, das wir von `anova_test()` schon kennen.

#### Komplexere Modelle

Komplexere Modelle mit mehreren Faktoren lassen sich natürlich auch realisieren. Dafür ein neues Beispiel: Im Datensatz `ChickWeight` wurde das Gewicht von Küken seit Geburt getrackt. Es sind verschiedene Messzeitpunkte und die Art der Ernährung enthalten.

```{r}
ChickWeight %>% 
  summary()

view(ChickWeight)
```

Hier schauen wir uns direkt nur `rstatix` an, da das die eindeutig angenehmere Umsetzung ist.

```{r}
# rstatix
# Schreibweise 1
ChickWeight %>% 
  anova_test(weight ~ Diet + Time + Error(Chick/Time))

# Schreibweise 2
ChickWeight %>% 
  anova_test(dv = weight,
             between = Diet,
             within = Time,
             wid = Chick)
```

Bei Daten mit Messwiederholung müssen wir spezifizieren, welcher Faktor mehrmals gemessen wurde und an welcher Variable erkannt wird, welche Messungen zu welchem "Probanden" gehören. In der Formelschreibweise lässt sich das durch den Term `Error(ProbandenID/wiederholterFaktor`) ausdrücken. In der Argumentschreibweise spezifizieren wir `within = wiederholterFaktor` und `wid = ProbandenID`

`anova_test()` testet netterweise die Sphärizität direkt mit. Wenn der Mauchly-Test signifikant wird, müssen wir die messwiederholten Faktoren (hier: Time und die Interaktion Diet:Time) im unteren Abschnitt des Outputs interpretieren. Die Spalten mit "GG" sind dabei korrigiert nach Greenhouse-Geisser, die Spalten mit "HF" nach Huynh-Feldt.

Kovariaten können wir in `anova_test()` über das Argument `covariate =` einfügen, so wie bei `dv =`, `between =` usw.

Noch mehr Faktoren/Variablen lassen sich über c() verknüpfen, z.B. `between = c(Diet, Species)`

#### Post Hoc Test

Wenn eine ANOVA signifikant wird, interessiert uns meistens noch, welche/r der Mittelwertsunterschiede dafür verantwortlich ist. Im Bezug auf unser Meerschweinchen-Beispiel hängt der Zahnwachstum offensichtlich von der Dosis ab, aber bisher wissen wir nicht, ob die höchste Dosis zu mehr Wachstum als die anderen beiden führt, oder ob sich alle signifikant voneinander unterscheiden, oder ob es nur einen Unterschied im Bezug zur niedrigsten Dosis gibt usw.

```{r post-hoc}
# base
TukeyHSD(tooth.aov)

# rstatix
tooth %>%
  tukey_hsd(len ~ dose)
```

Die Funktion `tukey_hsd` erlaubt als Input entweder eine Formel (wie hier) oder das Ergebnis von `aov()` oder `lm()`. Der Output von `anova_test()` funktioniert hier nicht als Input!

#### Nonparametrisch: Kruskal-Wallis Rank Sum Test

```{r}
# base
kruskal.test(tooth, len ~ dose)

# rstatix
tooth %>% 
  kruskal_test(len ~ dose)
```

## Zusammenhänge

### Korrelation

Ziel: Zusammenhang zwischen zwei Variablen feststellen

Datenstruktur: Zwei kontinuierliche Variablen

Als Beispiel haben wir den `cars` Datensatz, der Geschwindigkeit und Bremsweg von Autos enthält.

```{r daten korr}
get_summary_stats(cars)

ggplot(cars)+
  geom_point(aes(speed, dist))+
  theme_minimal()
```

```{r corr}
# r base
cor(cars$speed, cars$dist)

# rstatix
cars %>% 
  cor_test(speed, dist)

# psych
library(psych)
corr.test(cars$speed, cars$dist)
```

Base R kann Korrelationen berechnen, hat aber standardmäßig keinen Test auf Signifikanz enthalten. Hier wird der Nutzen von rstatix besonders deutlich.

Als Ergänzung noch die Funktion `corr.test()` aus dem `psych` Package.

#### Nonparametrisch: Spearman & Kendall

Nonparametrische Korrelationsberechnungen lassen sich über das Argument `method` spezifizieren.

```{r corr nonpara}
#| eval = FALSE
data %>% 
  cor_test(method = "Spearman") # oder auch Kendall
```

### Regression

Ziele:

-   Gruppenunterschiede feststellen

-   Werte vorhersagen

-   relevante Prädiktoren für eine bestimmte abhängige Variable identifizieren

-   Modell mit bestem Fit finden

Datenstruktur: kontinuierliche abhängige Variable & kategoriale/kontinuierliche Prädiktoren

Hier haben wir als Datenbeispiel den Datensatz `swiss`, in dem die Fertilität der Population der 47 französisch-sprachigen Provinzen in der Schweiz erfasst wurde. Die weiteren Variablen:

-   `Agriculture`: % of males involved in agriculture as occupation

-   `Examination`: % draftees receiving highest mark on army examination

-   `Education`: % education beyond primary school for draftees

-   `Catholic`: % 'catholic' (as opposed to 'protestant')

-   `Infant.Mortality`: live births who live less than 1 year

```{r}
swiss
```

```{r}
swiss.lm <- lm(Fertility ~ Agriculture + Examination + Education + Catholic, swiss)
summary(swiss.lm)

#funktioniert nicht:
# swiss %>% 
#   lm(Fertility ~ Agriculture)
```

Mit diesem Output können wir feststellen, welche Prädiktoren signifikant mit der Fertilität zusammenhängen, kontrolliert für die anderen Prädiktoren. Auch hier sehen wir wieder: `lm()` baut nur das Modell, erst `summary()` wertet es aus. In dem Fall gibt es kein Äquivalent von `rstatix`.

Wie oben erwähnt, kann ein anderes mögliches Ziel einer Regression sein, das Regressionsmodell mit dem besten Fit zu den Daten herauszufinden, also nur Prädiktoren nach dem Prinzip "so viel wie nötig, so wenig wie möglich" im finalen Modell zu behalten. Dafür werden mehrere Regressionsgleichungen bezüglich ihrer Varianzaufklärung miteinander verglichen.

```{r}
# Modelle bauen
swiss.lm1 <- lm(Fertility ~ 1, swiss)
swiss.lm2 <- update(swiss.lm1, ~. + Education)
swiss.lm3 <- update(swiss.lm2, ~. + Catholic)

# Modelle vergleichen
anova(swiss.lm1, swiss.lm2, swiss.lm3)
```

Mithilfe der Funktion `update()` können wir uns sparen, das bisherige Modell noch mal komplett einzutippen. Sie funktioniert nach dem Prinzip `update(altes Modell, neues Modell)`. Mit `~.` kürzen wir das alte Modell ab, danach ergänzen wir neue Prädiktoren und/oder Interaktionen.

Die Funktion `anova()` ist potentiell verwirrend: Wir rechnen hier offensichtlich keine ANOVA, wie wir sie weiter oben kennengelernt haben. Wir führen allerdings schon eine "Analyse der Varianzen" durch - nur beziehen sich die Varianzen auf jeweils die aufgeklärte Varianz der Regressionsmodelle. `anova()` kann als Input nur "fitted model objects" verwerten, also bereits erstellte Modelle, und gibt als Output einen Vergleich dieser Modelle.

Ansonsten lassen sich Messwiederholungen genauso wie in der "Formelschreibweise" der ANOVA über `+ Error(ProbandenID/messwiederholteVariable)` spezifizieren.

Interaktionen können wir in die Formel durch `*` oder `:` einbauen: `Fertility ~ Education*Catholic`

## Andere Ressourcen:

-   Überblick über `rstatx`-Funktionen: https://rpkgs.datanovia.com/rstatix/

-   Liste von Datasets, die direkt in base R abrufbar sind: https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html
