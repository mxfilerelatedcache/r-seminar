{
  "hash": "1b138fcbe9c122aa686ed49c593b612e",
  "result": {
    "markdown": "---\ntitle: \"Inferenzstatistik in R\"\nauthor: \"Kira Wolff & Simon Krukowski\"\nformat: html\neditor: visual\nexecute:\n  freeze: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rstatix)\nlibrary(ggplot2)\nlibrary(car)\nlibrary(nycflights13)\n```\n:::\n\n\n# Statistik\n\nHier beschäftigen wir uns mit den grundlegenden inferenzstatistischen Verfahren, die ihr aus den Bachelor-Vorlesungen Statistik 1 und 2 kennt.\n\nDas ist natürlich nur ein kleiner Einblick in die statistischen Verfahren, die mit R möglich sind. Es soll euch aber schon mal ein Gefühl für den grundlegenden Aufbau der Funktionen geben, sodass ihr ohne große Probleme auch andere Verfahren benutzen könnt. In vielen Fällen kommt man mit den grundlegenden Verfahren hier auch schon relativ weit.\n\n## Die Qual der Wahl\n\nÄhnlich wie ihr letzte Woche die Unterschiede zwischen base R und dplyr kennengelernt habt, gibt es auch für die inferenzstatistischen Verfahren verschiedene Packages und Funktionen, und damit Vorgehensweisen.\n\nGrundsätzlich gibt es hier keine richtigen oder falschen Packages, stattdessen hängt es vom Kontext ab. Manche Packages ermöglichen ziemlich komplexe Analysen, und um sich die als Möglichkeit offen zu lassen, kann es sich lohnen, auch direkt die \"einfachen\" Analysen eines Projekts damit zu rechnen, damit die verschiedenen Analysen kompatibler miteinander sind. Manche Packages sind von der Syntax möglichst eingängig gestaltet, sodass man als Anfänger besser abgeholt wird. Wiederum andere bieten die gleichen Funktionen, verwenden aber leicht unterschiedliche Berechnungsmethoden, da die Methoden für verschiedene Kontexte verschieden robust sind.\n\nMeistens macht es Sinn mit dem, was man kennt (bzw. was ihr hier kennenlernt), anzufangen. Wenn sich dann eine Datensituation ergibt, die komplexer ist, lässt sich immer noch im Internet recherchieren, welches Package/welche Funktion vielleicht besser geeignet sind. Die Hürde wird dann weniger euer R-Wissen sein, sondern eher euer allgemeines Statistik-Wissen. Unserer Erfahrung nach verbringt man eher mehr Zeit mit der Recherche von statistischen Methoden statt R-Funktionen.\n\nWie machen wir es hier? Wir zeigen euch die Funktionen von base R und vom Package `rstatix`, welches bewusst so gestaltet ist, damit es gut mit der Pipe und den dplyr-Funktionen funktioniert.\n\n## Voraussetzungen\n\nWie ihr wisst, gibt es für die sogennannten parametrischen Testverfahren bestimmte Voraussetzungen, die die Daten erfüllen sollten, damit die Tests anwendbar sind und die Auswertung angemessen. Vorbildlich wie wir sind, schauen wir uns diese Tests für die Voraussetzungen zuerst an.\n\n### Normalverteilung\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(dnorm, xlim=c(-3,3))\n```\n\n::: {.cell-output-display}\n![](content3_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# base\nshapiro.test(Daten$Spalte)\n\n# rstatix\ndata %>% \n  shapiro_test(Spalte)\n```\n:::\n\n\nDer Shapiro-Wilk Test testet, ob die Daten signifikant von einer Normalverteilung abweichen. Wenn er signifikant wird, sind die Daten also nicht normalverteilt.\n\nJe größer die Stichprobe ist, desto schlechter funktioniert der Shapiro-Wilk Test, da er dann tendenziell zu schnell signifikant wird, obwohl die Daten einigermaßen normalverteilt sind. Daher bietet es sich an, ab ca. n \\> 50 stattdessen einen QQ-Plot anzuschauen. Ab n \\> 5000 würde der Test nicht mehr ausgeführt werden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# normalverteilte Werte erzeugen\nvec.norm <- rnorm(100, mean = 0, sd=1)\n\n# QQ-Plot\nggplot()+\n  geom_qq(aes(sample=vec.norm))+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](content3_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(vec.norm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  vec.norm\nW = 0.9863, p-value = 0.3925\n```\n:::\n:::\n\n\nBei einem QQ-Plot werden die Werte, die wir testen, standardisiert und dann gegen die \"echte\" Standardnormalverteilung geplottet. Wenn unsere Daten perfekt (standard)normalverteilt wären, würde sich eine perfekte 45°-Gerade ergeben. Unsere künstlichen Daten oben sind auf jeden Fall nah genug an der \"perfekten Gerade\" dran.\n\nHier noch ein Beispiel, in dem die Daten nicht normalverteilt sind:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Daten aus nycflights13 package\nggplot(flights)+\n  geom_qq(aes(sample=air_time))+\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 9430 rows containing non-finite values (`stat_qq()`).\n```\n:::\n\n::: {.cell-output-display}\n![](content3_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nflights\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     1     1      533        529       4     850     830      20 UA     \n 3  2013     1     1      542        540       2     923     850      33 AA     \n 4  2013     1     1      544        545      -1    1004    1022     -18 B6     \n 5  2013     1     1      554        600      -6     812     837     -25 DL     \n 6  2013     1     1      554        558      -4     740     728      12 UA     \n 7  2013     1     1      555        600      -5     913     854      19 B6     \n 8  2013     1     1      557        600      -3     709     723     -14 EV     \n 9  2013     1     1      557        600      -3     838     846      -8 B6     \n10  2013     1     1      558        600      -2     753     745       8 AA     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n```\n:::\n\n```{.r .cell-code}\nggplot(flights)+\n  geom_qq(aes(sample=dep_delay))+\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 8255 rows containing non-finite values (`stat_qq()`).\n```\n:::\n\n::: {.cell-output-display}\n![](content3_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(flights$dep_delay)\n```\n\n::: {.cell-output-display}\n![](content3_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n:::\n\n\n### Varianzhomogenität\n\nBei der Varianzhomogenität geht es darum, dass unterschiedliche Gruppen bezüglich einer Variable die in etwa gleiche Varianz haben.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# rstatix\ndata %>% \n  levene_test(abhängigeVariable ~ Gruppe)\n\nflights %>% \n  levene_test(dep_delay ~ factor(month))\n```\n:::\n\n\n## Gruppenvergleiche\n\n### t-Test\n\nZiel: zwei Gruppen vergleichen\n\nDatenstruktur: kontinuierliche abhängige Variable & dichotome Gruppenvariable\n\nZur Veranschaulichung verwenden wir hier den Datensatz `ToothGrowth`: Hier wurde der Zahnwachstum von Meerschweinchen in Abhängigkeit von verabreichtem Vitamin C untersucht. Die Stichprobe besteht aus 60 Meerschweinchen und sowohl die Verabreichungsmethode (Orangensaft vs. Ascorbinsäure) als auch die Vitamin C-Dosis (0.5, 1 oder 2mg pro Tag) wurden variiert. Da wir beim t-Test nur mit zwei Gruppen arbeiten können, schauen wir uns jetzt nur die Unterschiede durch die Verabreichungsmethode an.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(ToothGrowth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      len        supp         dose      \n Min.   : 4.20   OJ:30   Min.   :0.500  \n 1st Qu.:13.07   VC:30   1st Qu.:0.500  \n Median :19.25           Median :1.000  \n Mean   :18.81           Mean   :1.167  \n 3rd Qu.:25.27           3rd Qu.:2.000  \n Max.   :33.90           Max.   :2.000  \n```\n:::\n\n```{.r .cell-code}\nview(ToothGrowth)\n\nToothGrowth %>% \n  get_summary_stats()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 13\n  variable     n   min   max median    q1    q3   iqr   mad  mean    sd    se\n  <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 len         60   4.2  33.9   19.2  13.1  25.3  12.2 9.04  18.8  7.65  0.988\n2 dose        60   0.5   2      1     0.5   2     1.5 0.741  1.17 0.629 0.081\n# … with 1 more variable: ci <dbl>\n```\n:::\n\n```{.r .cell-code}\ntooth <- ToothGrowth %>% \n            mutate(dose = as.factor(dose))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tooth)+\n  geom_boxplot(aes(x=supp, y=len))+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](content3_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n#### Funktionsaufbau\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Base: Format 1\nt.test(AV ~ group, data)\n\n# Base: Format 2\nt.test(daten$group1, daten$group2)\n\n# rstatix\ndata %>% \n  t_test(AV ~ group)\n```\n:::\n\n\nDie Tilde `~` ist das Zeichen in R, um einen Zusammenhang, eine Abhängigkeit oder ein Modell zu symbolisieren.\n\nNatürlich gibt es innerhalb von `t.test()/t_test()` mit Argumenten Möglichkeiten um\n\n-   einen t-Test für eine Stichprobe durchzuführen: z.B. `mu = 100`\n\n-   einen t-Test für abhängige Stichproben durchzuführen: `paired = TRUE`\n\n-   einen gerichteten t-Test durchzuführen: z.B. `alternative = \"less\"`\n\n-   bei nicht vorliegender Varianzhomogenität stattdessen den Welch-Test anzuwenden: `var.equal = FALSE`\n\n#### Funktionsanwendung\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Base: Format 1\nt.base <- t.test(len ~ supp, tooth, var.equal = TRUE)\nt.base\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  len by supp\nt = 1.9153, df = 58, p-value = 0.06039\nalternative hypothesis: true difference in means between group OJ and group VC is not equal to 0\n95 percent confidence interval:\n -0.1670064  7.5670064\nsample estimates:\nmean in group OJ mean in group VC \n        20.66333         16.96333 \n```\n:::\n\n```{.r .cell-code}\n# rstatix\nt.rstatix <- tooth %>% \n                t_test(len ~ supp,var.equal = TRUE)\nt.rstatix\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic    df      p\n* <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl>  <dbl>\n1 len   OJ     VC        30    30      1.92    58 0.0604\n```\n:::\n\n```{.r .cell-code}\n# Normalerweise würde ich die Ergebnisse nicht als Objekte speichern, dient hier nur der Demonstration.\n```\n:::\n\n\nUnterschied zwischen base und rstatix:\n\n-   Liste vs. tibble\n\n-   base: Zusatzinfos - Zuordnung, Verständnis\n\n-   rstatix: Formatierung als Tabelle\n\n-   rstatix garantiert pipe-Kompatibilität, funktioniert bei Base-Funktionen nicht immer (aber manchmal)\n\nEuch wird im Laufe der kommenden Funktionen auffallen, dass die `rstatix` Funktionen netterweise fast immer exakt so heißen wie die `base` Funktionen, nur das statt `.` ein `_` verwendet wird: `t.test()` vs. `t_test()`\n\n#### Nonparametrisch: Wilcoxon Rank Sum Test\n\nReminder: Wenn Voraussetzungen nicht erfüllt sein sollten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Base\nwilcox.test(len ~ supp, tooth)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in wilcox.test.default(x = c(15.2, 21.5, 17.6, 9.7, 14.5, 10, 8.2, :\ncannot compute exact p-value with ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  len by supp\nW = 575.5, p-value = 0.06449\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n\n```{.r .cell-code}\n# rstatix\ntooth %>% \n  wilcox_test(len ~ supp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  .y.   group1 group2    n1    n2 statistic      p\n* <chr> <chr>  <chr>  <int> <int>     <dbl>  <dbl>\n1 len   OJ     VC        30    30      576. 0.0645\n```\n:::\n:::\n\n\n### ANOVA\n\nZiel: Zwei oder mehr Gruppen vergleichen.\n\nWir können hier bei den Meerschweinchendaten bleiben, da die Dosis-Variable drei Faktorstufen hat.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#base\ntooth.aov <- aov(len ~ dose, tooth)\nsummary(tooth.aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ndose         2   2426    1213   67.42 9.53e-16 ***\nResiduals   57   1026      18                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#funktioniert nicht:\n\n#tooth %>% \n#  aov(len ~ dose) %>% \n#  summary()\n\n\n#rstatix\n## Schreibweise 1\ntooth %>%\n  anova_test(len ~ dose)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nANOVA Table (type II tests)\n\n  Effect DFn DFd      F        p p<.05   ges\n1   dose   2  57 67.416 9.53e-16     * 0.703\n```\n:::\n\n```{.r .cell-code}\n## Schreibweise 2\ntooth %>%\n  anova_test(dv = len,\n             between = dose)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nANOVA Table (type II tests)\n\n  Effect DFn DFd      F        p p<.05   ges\n1   dose   2  57 67.416 9.53e-16     * 0.703\n```\n:::\n\n```{.r .cell-code}\n# Hybrid aus base und rstatix\nanova_summary(tooth.aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Effect DFn DFd      F        p p<.05   ges\n1      1   2  57 67.416 9.53e-16     1 0.703\n```\n:::\n:::\n\n\nDie Funktion `aov()` steht natürlich für \"analysis of variances\". Die Funktion gibt uns nicht direkt das Ergebnis, was wir von einer ANOVA erwarten, sondern fittet (=\"baut\") erst mal nur das Modell. Wenn wir das ANOVA-Modell auswerten wollen, müssen wir uns das aov-Ergebnis über `summary()` zusammenfassen lassen.\n\nDie Funktion `anova_test()` gibt uns direkt das erwartete Ergebnis aus. Innerhalb der Funktion gibt es zwei mögliche Schreibweisen, um das Modell zu spezifizieren: Entweder über die Tilde, oder indem wir Rollen der Variablen separat über die Argumente spezifizieren.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hybrid aus base und rstatix\nanova_summary(tooth.aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Effect DFn DFd      F        p p<.05   ges\n1      1   2  57 67.416 9.53e-16     1 0.703\n```\n:::\n:::\n\n\n`anova_summary()` kann Outputs von `aov()` verwerten und verpackt sie in das praktische dataframe-Format, das wir von `anova_test()` schon kennen.\n\n#### Komplexere Modelle\n\nKomplexere Modelle mit mehreren Faktoren lassen sich natürlich auch realisieren. Dafür ein neues Beispiel: Im Datensatz `ChickWeight` wurde das Gewicht von Küken seit Geburt getrackt. Es sind verschiedene Messzeitpunkte und die Art der Ernährung enthalten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nChickWeight %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     weight           Time           Chick     Diet   \n Min.   : 35.0   Min.   : 0.00   13     : 12   1:220  \n 1st Qu.: 63.0   1st Qu.: 4.00   9      : 12   2:120  \n Median :103.0   Median :10.00   20     : 12   3:120  \n Mean   :121.8   Mean   :10.72   10     : 12   4:118  \n 3rd Qu.:163.8   3rd Qu.:16.00   17     : 12          \n Max.   :373.0   Max.   :21.00   19     : 12          \n                                 (Other):506          \n```\n:::\n\n```{.r .cell-code}\nview(ChickWeight)\n```\n:::\n\n\nHier schauen wir uns direkt nur `rstatix` an, da das die eindeutig angenehmere Umsetzung ist.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# rstatix\n# Schreibweise 1\nChickWeight %>% \n  anova_test(weight ~ Diet + Time + Error(Chick/Time))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nANOVA Table (type III tests)\n\n$ANOVA\n     Effect DFn DFd       F         p p<.05   ges\n1      Diet   3  41   5.075  4.00e-03     * 0.161\n2      Time  11 451 280.945 6.41e-194     * 0.769\n3 Diet:Time  33 451   3.766  9.34e-11     * 0.118\n\n$`Mauchly's Test for Sphericity`\n     Effect        W         p p<.05\n1      Time 2.68e-17 1.03e-251     *\n2 Diet:Time 2.68e-17 1.03e-251     *\n\n$`Sphericity Corrections`\n     Effect   GGe      DF[GG]    p[GG] p[GG]<.05   HFe      DF[HF]    p[HF]\n1      Time 0.114 1.26, 51.48 2.01e-24         * 0.116 1.28, 52.34 8.63e-25\n2 Diet:Time 0.114 3.77, 51.48 1.00e-02         * 0.116 3.83, 52.34 1.00e-02\n  p[HF]<.05\n1         *\n2         *\n```\n:::\n\n```{.r .cell-code}\n# Schreibweise 2\nChickWeight %>% \n  anova_test(dv = weight,\n             between = Diet,\n             within = Time,\n             wid = Chick)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nANOVA Table (type III tests)\n\n$ANOVA\n     Effect DFn DFd       F         p p<.05   ges\n1      Diet   3  41   5.075  4.00e-03     * 0.161\n2      Time  11 451 280.945 6.41e-194     * 0.769\n3 Diet:Time  33 451   3.766  9.34e-11     * 0.118\n\n$`Mauchly's Test for Sphericity`\n     Effect        W         p p<.05\n1      Time 2.68e-17 1.03e-251     *\n2 Diet:Time 2.68e-17 1.03e-251     *\n\n$`Sphericity Corrections`\n     Effect   GGe      DF[GG]    p[GG] p[GG]<.05   HFe      DF[HF]    p[HF]\n1      Time 0.114 1.26, 51.48 2.01e-24         * 0.116 1.28, 52.34 8.63e-25\n2 Diet:Time 0.114 3.77, 51.48 1.00e-02         * 0.116 3.83, 52.34 1.00e-02\n  p[HF]<.05\n1         *\n2         *\n```\n:::\n:::\n\n\nBei Daten mit Messwiederholung müssen wir spezifizieren, welcher Faktor mehrmals gemessen wurde und an welcher Variable erkannt wird, welche Messungen zu welchem \"Probanden\" gehören. In der Formelschreibweise lässt sich das durch den Term `Error(ProbandenID/wiederholterFaktor`) ausdrücken. In der Argumentschreibweise spezifizieren wir `within = wiederholterFaktor` und `wid = ProbandenID`\n\n`anova_test()` testet netterweise die Sphärizität direkt mit. Wenn der Mauchly-Test signifikant wird, müssen wir die messwiederholten Faktoren (hier: Time und die Interaktion Diet:Time) im unteren Abschnitt des Outputs interpretieren. Die Spalten mit \"GG\" sind dabei korrigiert nach Greenhouse-Geisser, die Spalten mit \"HF\" nach Huynh-Feldt.\n\nKovariaten können wir in `anova_test()` über das Argument `covariate =` einfügen, so wie bei `dv =`, `between =` usw.\n\nNoch mehr Faktoren/Variablen lassen sich über c() verknüpfen, z.B. `between = c(Diet, Species)`\n\n#### Post Hoc Test\n\nWenn eine ANOVA signifikant wird, interessiert uns meistens noch, welche/r der Mittelwertsunterschiede dafür verantwortlich ist. Im Bezug auf unser Meerschweinchen-Beispiel hängt der Zahnwachstum offensichtlich von der Dosis ab, aber bisher wissen wir nicht, ob die höchste Dosis zu mehr Wachstum als die anderen beiden führt, oder ob sich alle signifikant voneinander unterscheiden, oder ob es nur einen Unterschied im Bezug zur niedrigsten Dosis gibt usw.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# base\nTukeyHSD(tooth.aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = len ~ dose, data = tooth)\n\n$dose\n        diff       lwr       upr    p adj\n1-0.5  9.130  5.901805 12.358195 0.00e+00\n2-0.5 15.495 12.266805 18.723195 0.00e+00\n2-1    6.365  3.136805  9.593195 4.25e-05\n```\n:::\n\n```{.r .cell-code}\n# rstatix\ntooth %>%\n  tukey_hsd(len ~ dose)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 9\n  term  group1 group2 null.value estimate conf.low conf.high    p.adj p.adj.si…¹\n* <chr> <chr>  <chr>       <dbl>    <dbl>    <dbl>     <dbl>    <dbl> <chr>     \n1 dose  0.5    1               0     9.13     5.90     12.4  2   e- 8 ****      \n2 dose  0.5    2               0    15.5     12.3      18.7  1.12e-11 ****      \n3 dose  1      2               0     6.36     3.14      9.59 4.25e- 5 ****      \n# … with abbreviated variable name ¹​p.adj.signif\n```\n:::\n:::\n\n\nDie Funktion `tukey_hsd` erlaubt als Input entweder eine Formel (wie hier) oder das Ergebnis von `aov()` oder `lm()`. Der Output von `anova_test()` funktioniert hier nicht als Input!\n\n#### Nonparametrisch: Kruskal-Wallis Rank Sum Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# base\nkruskal.test(tooth, len ~ dose)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in kruskal.test.default(tooth, len ~ dose): 'x' is a list, so ignoring\nargument 'g'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in kruskal.test.default(tooth, len ~ dose): some elements of 'x' are not\nnumeric and will be coerced to numeric\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  tooth\nKruskal-Wallis chi-squared = 129.49, df = 2, p-value < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# rstatix\ntooth %>% \n  kruskal_test(len ~ dose)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 6\n  .y.       n statistic    df             p method        \n* <chr> <int>     <dbl> <int>         <dbl> <chr>         \n1 len      60      40.7     2 0.00000000148 Kruskal-Wallis\n```\n:::\n:::\n\n\n## Zusammenhänge\n\n### Korrelation\n\nZiel: Zusammenhang zwischen zwei Variablen feststellen\n\nDatenstruktur: Zwei kontinuierliche Variablen\n\nAls Beispiel haben wir den `cars` Datensatz, der Geschwindigkeit und Bremsweg von Autos enthält.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_summary_stats(cars)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 13\n  variable     n   min   max median    q1    q3   iqr   mad  mean    sd    se\n  <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 speed       50     4    25     15    12    19     7  5.93  15.4  5.29 0.748\n2 dist        50     2   120     36    26    56    30 23.7   43.0 25.8  3.64 \n# … with 1 more variable: ci <dbl>\n```\n:::\n\n```{.r .cell-code}\nggplot(cars)+\n  geom_point(aes(speed, dist))+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](content3_files/figure-html/daten korr-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# r base\ncor(cars$speed, cars$dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8068949\n```\n:::\n\n```{.r .cell-code}\n# rstatix\ncars %>% \n  cor_test(speed, dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  var1  var2    cor statistic        p conf.low conf.high method \n  <chr> <chr> <dbl>     <dbl>    <dbl>    <dbl>     <dbl> <chr>  \n1 speed dist   0.81      9.46 1.49e-12    0.682     0.886 Pearson\n```\n:::\n\n```{.r .cell-code}\n# psych\nlibrary(psych)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'psych'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:car':\n\n    logit\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n```\n:::\n\n```{.r .cell-code}\ncorr.test(cars$speed, cars$dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:corr.test(x = cars$speed, y = cars$dist)\nCorrelation matrix \n[1] 0.81\nSample Size \n[1] 50\nThese are the unadjusted probability values.\n  The probability values  adjusted for multiple tests are in the p.adj object. \n[1] 0\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n```\n:::\n:::\n\n\nBase R kann Korrelationen berechnen, hat aber standardmäßig keinen Test auf Signifikanz enthalten. Hier wird der Nutzen von rstatix besonders deutlich.\n\nAls Ergänzung noch die Funktion `corr.test()` aus dem `psych` Package.\n\n#### Nonparametrisch: Spearman & Kendall\n\nNonparametrische Korrelationsberechnungen lassen sich über das Argument `method` spezifizieren.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n  cor_test(method = \"Spearman\") # oder auch Kendall\n```\n:::\n\n\n### Regression\n\nZiele:\n\n-   Gruppenunterschiede feststellen\n\n-   Werte vorhersagen\n\n-   relevante Prädiktoren für eine bestimmte abhängige Variable identifizieren\n\n-   Modell mit bestem Fit finden\n\nDatenstruktur: kontinuierliche abhängige Variable & kategoriale/kontinuierliche Prädiktoren\n\nHier haben wir als Datenbeispiel den Datensatz `swiss`, in dem die Fertilität der Population der 47 französisch-sprachigen Provinzen in der Schweiz erfasst wurde. Die weiteren Variablen:\n\n-   `Agriculture`: % of males involved in agriculture as occupation\n\n-   `Examination`: % draftees receiving highest mark on army examination\n\n-   `Education`: % education beyond primary school for draftees\n\n-   `Catholic`: % 'catholic' (as opposed to 'protestant')\n\n-   `Infant.Mortality`: live births who live less than 1 year\n\n\n::: {.cell}\n\n```{.r .cell-code}\nswiss\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Fertility Agriculture Examination Education Catholic\nCourtelary        80.2        17.0          15        12     9.96\nDelemont          83.1        45.1           6         9    84.84\nFranches-Mnt      92.5        39.7           5         5    93.40\nMoutier           85.8        36.5          12         7    33.77\nNeuveville        76.9        43.5          17        15     5.16\nPorrentruy        76.1        35.3           9         7    90.57\nBroye             83.8        70.2          16         7    92.85\nGlane             92.4        67.8          14         8    97.16\nGruyere           82.4        53.3          12         7    97.67\nSarine            82.9        45.2          16        13    91.38\nVeveyse           87.1        64.5          14         6    98.61\nAigle             64.1        62.0          21        12     8.52\nAubonne           66.9        67.5          14         7     2.27\nAvenches          68.9        60.7          19        12     4.43\nCossonay          61.7        69.3          22         5     2.82\nEchallens         68.3        72.6          18         2    24.20\nGrandson          71.7        34.0          17         8     3.30\nLausanne          55.7        19.4          26        28    12.11\nLa Vallee         54.3        15.2          31        20     2.15\nLavaux            65.1        73.0          19         9     2.84\nMorges            65.5        59.8          22        10     5.23\nMoudon            65.0        55.1          14         3     4.52\nNyone             56.6        50.9          22        12    15.14\nOrbe              57.4        54.1          20         6     4.20\nOron              72.5        71.2          12         1     2.40\nPayerne           74.2        58.1          14         8     5.23\nPaysd'enhaut      72.0        63.5           6         3     2.56\nRolle             60.5        60.8          16        10     7.72\nVevey             58.3        26.8          25        19    18.46\nYverdon           65.4        49.5          15         8     6.10\nConthey           75.5        85.9           3         2    99.71\nEntremont         69.3        84.9           7         6    99.68\nHerens            77.3        89.7           5         2   100.00\nMartigwy          70.5        78.2          12         6    98.96\nMonthey           79.4        64.9           7         3    98.22\nSt Maurice        65.0        75.9           9         9    99.06\nSierre            92.2        84.6           3         3    99.46\nSion              79.3        63.1          13        13    96.83\nBoudry            70.4        38.4          26        12     5.62\nLa Chauxdfnd      65.7         7.7          29        11    13.79\nLe Locle          72.7        16.7          22        13    11.22\nNeuchatel         64.4        17.6          35        32    16.92\nVal de Ruz        77.6        37.6          15         7     4.97\nValdeTravers      67.6        18.7          25         7     8.65\nV. De Geneve      35.0         1.2          37        53    42.34\nRive Droite       44.7        46.6          16        29    50.43\nRive Gauche       42.8        27.7          22        29    58.33\n             Infant.Mortality\nCourtelary               22.2\nDelemont                 22.2\nFranches-Mnt             20.2\nMoutier                  20.3\nNeuveville               20.6\nPorrentruy               26.6\nBroye                    23.6\nGlane                    24.9\nGruyere                  21.0\nSarine                   24.4\nVeveyse                  24.5\nAigle                    16.5\nAubonne                  19.1\nAvenches                 22.7\nCossonay                 18.7\nEchallens                21.2\nGrandson                 20.0\nLausanne                 20.2\nLa Vallee                10.8\nLavaux                   20.0\nMorges                   18.0\nMoudon                   22.4\nNyone                    16.7\nOrbe                     15.3\nOron                     21.0\nPayerne                  23.8\nPaysd'enhaut             18.0\nRolle                    16.3\nVevey                    20.9\nYverdon                  22.5\nConthey                  15.1\nEntremont                19.8\nHerens                   18.3\nMartigwy                 19.4\nMonthey                  20.2\nSt Maurice               17.8\nSierre                   16.3\nSion                     18.1\nBoudry                   20.3\nLa Chauxdfnd             20.5\nLe Locle                 18.9\nNeuchatel                23.0\nVal de Ruz               20.0\nValdeTravers             19.5\nV. De Geneve             18.0\nRive Droite              18.2\nRive Gauche              19.3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nswiss.lm <- lm(Fertility ~ Agriculture + Examination + Education + Catholic, swiss)\nsummary(swiss.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Fertility ~ Agriculture + Examination + Education + \n    Catholic, data = swiss)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7813  -6.3308   0.8113   5.7205  15.5569 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 91.05542    6.94881  13.104  < 2e-16 ***\nAgriculture -0.22065    0.07360  -2.998  0.00455 ** \nExamination -0.26058    0.27411  -0.951  0.34722    \nEducation   -0.96161    0.19455  -4.943 1.28e-05 ***\nCatholic     0.12442    0.03727   3.339  0.00177 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.736 on 42 degrees of freedom\nMultiple R-squared:  0.6498,\tAdjusted R-squared:  0.6164 \nF-statistic: 19.48 on 4 and 42 DF,  p-value: 3.95e-09\n```\n:::\n\n```{.r .cell-code}\n#funktioniert nicht:\n# swiss %>% \n#   lm(Fertility ~ Agriculture)\n```\n:::\n\n\nMit diesem Output können wir feststellen, welche Prädiktoren signifikant mit der Fertilität zusammenhängen, kontrolliert für die anderen Prädiktoren. Auch hier sehen wir wieder: `lm()` baut nur das Modell, erst `summary()` wertet es aus. In dem Fall gibt es kein Äquivalent von `rstatix`.\n\nWie oben erwähnt, kann ein anderes mögliches Ziel einer Regression sein, das Regressionsmodell mit dem besten Fit zu den Daten herauszufinden, also nur Prädiktoren nach dem Prinzip \"so viel wie nötig, so wenig wie möglich\" im finalen Modell zu behalten. Dafür werden mehrere Regressionsgleichungen bezüglich ihrer Varianzaufklärung miteinander verglichen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelle bauen\nswiss.lm1 <- lm(Fertility ~ 1, swiss)\nswiss.lm2 <- update(swiss.lm1, ~. + Education)\nswiss.lm3 <- update(swiss.lm2, ~. + Catholic)\n\n# Modelle vergleichen\nanova(swiss.lm1, swiss.lm2, swiss.lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: Fertility ~ 1\nModel 2: Fertility ~ Education\nModel 3: Fertility ~ Education + Catholic\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1     46 7178.0                                  \n2     45 4015.2  1    3162.7 45.564  2.66e-08 ***\n3     44 3054.2  1     961.1 13.846 0.0005598 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nMithilfe der Funktion `update()` können wir uns sparen, das bisherige Modell noch mal komplett einzutippen. Sie funktioniert nach dem Prinzip `update(altes Modell, neues Modell)`. Mit `~.` kürzen wir das alte Modell ab, danach ergänzen wir neue Prädiktoren und/oder Interaktionen.\n\nDie Funktion `anova()` ist potentiell verwirrend: Wir rechnen hier offensichtlich keine ANOVA, wie wir sie weiter oben kennengelernt haben. Wir führen allerdings schon eine \"Analyse der Varianzen\" durch - nur beziehen sich die Varianzen auf jeweils die aufgeklärte Varianz der Regressionsmodelle. `anova()` kann als Input nur \"fitted model objects\" verwerten, also bereits erstellte Modelle, und gibt als Output einen Vergleich dieser Modelle.\n\nAnsonsten lassen sich Messwiederholungen genauso wie in der \"Formelschreibweise\" der ANOVA über `+ Error(ProbandenID/messwiederholteVariable)` spezifizieren.\n\nInteraktionen können wir in die Formel durch `*` oder `:` einbauen: `Fertility ~ Education*Catholic`\n\n## Andere Ressourcen:\n\n-   Überblick über `rstatx`-Funktionen: https://rpkgs.datanovia.com/rstatix/\n\n-   Liste von Datasets, die direkt in base R abrufbar sind: https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html\n",
    "supporting": [
      "content3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}